{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010148,
     "end_time": "2021-02-15T17:13:40.839219",
     "exception": false,
     "start_time": "2021-02-15T17:13:40.829071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-15T17:13:40.863763Z",
     "iopub.status.busy": "2021-02-15T17:13:40.862878Z",
     "iopub.status.idle": "2021-02-15T17:13:47.408261Z",
     "shell.execute_reply": "2021-02-15T17:13:47.408842Z"
    },
    "papermill": {
     "duration": 6.560838,
     "end_time": "2021-02-15T17:13:47.409209",
     "exception": false,
     "start_time": "2021-02-15T17:13:40.848371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-15T17:13:47.448649Z",
     "iopub.status.busy": "2021-02-15T17:13:47.447855Z",
     "iopub.status.idle": "2021-02-15T17:13:47.462078Z",
     "shell.execute_reply": "2021-02-15T17:13:47.461350Z"
    },
    "papermill": {
     "duration": 0.043771,
     "end_time": "2021-02-15T17:13:47.462239",
     "exception": false,
     "start_time": "2021-02-15T17:13:47.418468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_ckpt_to_h5(path_h5, path_ckpt, keras_model, use_ema=True):\n",
    "  \"\"\"Map the weights in checkpoint file (tf) to h5 file (keras).\n",
    "  Args:\n",
    "    path_h5: str, path to output hdf5 file to write weights loaded from ckpt\n",
    "      files.\n",
    "    path_ckpt: str, path to the ckpt files (e.g. 'efficientnet-b0/model.ckpt')\n",
    "      that records efficientnet weights from original repo\n",
    "      https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet\n",
    "    keras_model: keras model, built from keras.applications efficientnet\n",
    "      functions (e.g. EfficientNetB0)\n",
    "    use_ema: Bool, whether to use ExponentialMovingAverage result or not\n",
    "  \"\"\"\n",
    "  model_name_keras = keras_model.name\n",
    "  model_name_tf = model_name_keras.replace('efficientnet', 'efficientnet-')\n",
    "\n",
    "  keras_weight_names = [w.name for w in keras_model.weights]\n",
    "  tf_weight_names = get_variable_names_from_ckpt(path_ckpt)\n",
    "\n",
    "  keras_blocks = get_keras_blocks(keras_weight_names)\n",
    "  tf_blocks = get_tf_blocks(tf_weight_names)\n",
    "\n",
    "  print('check variables match in each block')\n",
    "  for keras_block, tf_block in zip(keras_blocks, tf_blocks):\n",
    "    check_match(keras_block, tf_block, keras_weight_names, tf_weight_names,\n",
    "                model_name_tf)\n",
    "    print('{} and {} match.'.format(tf_block, keras_block))\n",
    "\n",
    "  block_mapping = {x[0]: x[1] for x in zip(keras_blocks, tf_blocks)}\n",
    "\n",
    "  changed_weights = 0\n",
    "  for w in keras_model.weights:\n",
    "    if 'block' in w.name:\n",
    "      # example: 'block1a_dwconv/depthwise_kernel:0' -> 'block1a'\n",
    "      keras_block = w.name.split('/')[0].split('_')[0]\n",
    "      tf_block = block_mapping[keras_block]\n",
    "      tf_name = keras_name_to_tf_name_block(\n",
    "          w.name,\n",
    "          keras_block=keras_block,\n",
    "          tf_block=tf_block,\n",
    "          use_ema=use_ema,\n",
    "          model_name_tf=model_name_tf)\n",
    "    elif any([x in w.name for x in ['stem', 'top', 'predictions', 'probs']]):\n",
    "      tf_name = keras_name_to_tf_name_stem_top(\n",
    "          w.name, use_ema=use_ema, model_name_tf=model_name_tf)\n",
    "    elif 'normalization' in w.name:\n",
    "      print('skipping variable {}: normalization is a layer'\n",
    "            'in keras implementation, but preprocessing in '\n",
    "            'TF implementation.'.format(w.name))\n",
    "      continue\n",
    "    else:\n",
    "      raise ValueError('{} failed to parse.'.format(w.name))\n",
    "\n",
    "    try:\n",
    "      w_tf = tf.train.load_variable(path_ckpt, tf_name)\n",
    "      if (w.value().numpy() != w_tf).any():\n",
    "        w.assign(w_tf)\n",
    "        changed_weights += 1\n",
    "    except ValueError as e:\n",
    "      if any([x in w.name for x in ['top', 'predictions', 'probs']]):\n",
    "        warnings.warn('Fail to load top layer variable {}'\n",
    "                      'from {} because of {}.'.format(w.name, tf_name, e))\n",
    "      else:\n",
    "        raise ValueError('Fail to load {} from {}'.format(w.name, tf_name))\n",
    "\n",
    "  total_weights = len(keras_model.weights)\n",
    "  print('{}/{} weights updated'.format(changed_weights, total_weights))\n",
    "  keras_model.save_weights(path_h5)\n",
    "\n",
    "\n",
    "def get_variable_names_from_ckpt(path_ckpt, use_ema=True):\n",
    "  \"\"\"Get list of tensor names from checkpoint.\n",
    "  Args:\n",
    "    path_ckpt: str, path to the ckpt files\n",
    "    use_ema: Bool, whether to use ExponentialMovingAverage result or not.\n",
    "  Returns:\n",
    "    List of variable names from checkpoint.\n",
    "  \"\"\"\n",
    "  v_all = tf.train.list_variables(path_ckpt)\n",
    "\n",
    "  # keep name only\n",
    "  v_name_all = [x[0] for x in v_all]\n",
    "\n",
    "  if use_ema:\n",
    "    v_name_all = [x for x in v_name_all if 'ExponentialMovingAverage' in x]\n",
    "  else:\n",
    "    v_name_all = [x for x in v_name_all if 'ExponentialMovingAverage' not in x]\n",
    "\n",
    "  # remove util variables used for RMSprop\n",
    "  v_name_all = [x for x in v_name_all if 'RMS' not in x]\n",
    "  return v_name_all\n",
    "\n",
    "\n",
    "def get_tf_blocks(tf_weight_names):\n",
    "  \"\"\"Extract the block names from list of full weight names.\"\"\"\n",
    "  # Example: 'efficientnet-b0/blocks_0/conv2d/kernel' -> 'blocks_0'\n",
    "  tf_blocks = {x.split('/')[1] for x in tf_weight_names if 'block' in x}\n",
    "  # sort by number\n",
    "  tf_blocks = sorted(tf_blocks, key=lambda x: int(x.split('_')[1]))\n",
    "  return tf_blocks\n",
    "\n",
    "\n",
    "def get_keras_blocks(keras_weight_names):\n",
    "  \"\"\"Extract the block names from list of full weight names.\"\"\"\n",
    "  # example: 'block1a_dwconv/depthwise_kernel:0' -> 'block1a'\n",
    "  keras_blocks = {x.split('_')[0] for x in keras_weight_names if 'block' in x}\n",
    "  return sorted(keras_blocks)\n",
    "\n",
    "\n",
    "def keras_name_to_tf_name_stem_top(keras_name,\n",
    "                                   use_ema=True,\n",
    "                                   model_name_tf='efficientnet-b0'):\n",
    "  \"\"\"Mapping name in h5 to ckpt that is in stem or top (head).\n",
    "  we map name keras_name that points to a weight in h5 file\n",
    "  to a name of weight in ckpt file.\n",
    "  Args:\n",
    "    keras_name: str, the name of weight in the h5 file of keras implementation\n",
    "    use_ema: Bool, use the ExponentialMovingAverage resuolt in ckpt or not\n",
    "    model_name_tf: str, the name of model in ckpt.\n",
    "  Returns:\n",
    "    String for the name of weight as in ckpt file.\n",
    "  Raises:\n",
    "    KeyError: if we cannot parse the keras_name.\n",
    "  \"\"\"\n",
    "  if use_ema:\n",
    "    ema = '/ExponentialMovingAverage'\n",
    "  else:\n",
    "    ema = ''\n",
    "\n",
    "  stem_top_dict = {\n",
    "      'probs/bias:0': '{}/head/dense/bias{}',\n",
    "      'probs/kernel:0': '{}/head/dense/kernel{}',\n",
    "      'predictions/bias:0': '{}/head/dense/bias{}',\n",
    "      'predictions/kernel:0': '{}/head/dense/kernel{}',\n",
    "      'stem_conv/kernel:0': '{}/stem/conv2d/kernel{}',\n",
    "      'top_conv/kernel:0': '{}/head/conv2d/kernel{}',\n",
    "  }\n",
    "  for x in stem_top_dict:\n",
    "    stem_top_dict[x] = stem_top_dict[x].format(model_name_tf, ema)\n",
    "\n",
    "  # stem batch normalization\n",
    "  for bn_weights in ['beta', 'gamma', 'moving_mean', 'moving_variance']:\n",
    "    tf_name = '{}/stem/tpu_batch_normalization/{}{}'.format(\n",
    "        model_name_tf, bn_weights, ema)\n",
    "    stem_top_dict['stem_bn/{}:0'.format(bn_weights)] = tf_name\n",
    "\n",
    "  # top / head batch normalization\n",
    "  for bn_weights in ['beta', 'gamma', 'moving_mean', 'moving_variance']:\n",
    "    tf_name = '{}/head/tpu_batch_normalization/{}{}'.format(\n",
    "        model_name_tf, bn_weights, ema)\n",
    "    stem_top_dict['top_bn/{}:0'.format(bn_weights)] = tf_name\n",
    "\n",
    "  if keras_name in stem_top_dict:\n",
    "    return stem_top_dict[keras_name]\n",
    "  raise KeyError('{} from h5 file cannot be parsed'.format(keras_name))\n",
    "\n",
    "\n",
    "def keras_name_to_tf_name_block(keras_name,\n",
    "                                keras_block='block1a',\n",
    "                                tf_block='blocks_0',\n",
    "                                use_ema=True,\n",
    "                                model_name_tf='efficientnet-b0'):\n",
    "  \"\"\"Mapping name in h5 to ckpt that belongs to a block.\n",
    "  we map name keras_name that points to a weight in h5 file\n",
    "  to a name of weight in ckpt file.\n",
    "  Args:\n",
    "    keras_name: str, the name of weight in the h5 file of keras implementation\n",
    "    keras_block: str, the block name for keras implementation (e.g. 'block1a')\n",
    "    tf_block: str, the block name for tf implementation (e.g. 'blocks_0')\n",
    "    use_ema: Bool, use the ExponentialMovingAverage resuolt in ckpt or not\n",
    "    model_name_tf: str, the name of model in ckpt.\n",
    "  Returns:\n",
    "    String for the name of weight as in ckpt file.\n",
    "  Raises:\n",
    "    ValueError if keras_block does not show up in keras_name\n",
    "  \"\"\"\n",
    "\n",
    "  if keras_block not in keras_name:\n",
    "    raise ValueError('block name {} not found in {}'.format(\n",
    "        keras_block, keras_name))\n",
    "\n",
    "  # all blocks in the first group will not have expand conv and bn\n",
    "  is_first_blocks = (keras_block[5] == '1')\n",
    "\n",
    "  tf_name = [model_name_tf, tf_block]\n",
    "\n",
    "  # depthwide conv\n",
    "  if 'dwconv' in keras_name:\n",
    "    tf_name.append('depthwise_conv2d')\n",
    "    tf_name.append('depthwise_kernel')\n",
    "\n",
    "  # conv layers\n",
    "  if is_first_blocks:\n",
    "    # first blocks only have one conv2d\n",
    "    if 'project_conv' in keras_name:\n",
    "      tf_name.append('conv2d')\n",
    "      tf_name.append('kernel')\n",
    "  else:\n",
    "    if 'project_conv' in keras_name:\n",
    "      tf_name.append('conv2d_1')\n",
    "      tf_name.append('kernel')\n",
    "    elif 'expand_conv' in keras_name:\n",
    "      tf_name.append('conv2d')\n",
    "      tf_name.append('kernel')\n",
    "\n",
    "  # squeeze expansion layers\n",
    "  if '_se_' in keras_name:\n",
    "    if 'reduce' in keras_name:\n",
    "      tf_name.append('se/conv2d')\n",
    "    elif 'expand' in keras_name:\n",
    "      tf_name.append('se/conv2d_1')\n",
    "\n",
    "    if 'kernel' in keras_name:\n",
    "      tf_name.append('kernel')\n",
    "    elif 'bias' in keras_name:\n",
    "      tf_name.append('bias')\n",
    "\n",
    "  # batch normalization layers\n",
    "  if 'bn' in keras_name:\n",
    "    if is_first_blocks:\n",
    "      if 'project' in keras_name:\n",
    "        tf_name.append('tpu_batch_normalization_1')\n",
    "      else:\n",
    "        tf_name.append('tpu_batch_normalization')\n",
    "    else:\n",
    "      if 'project' in keras_name:\n",
    "        tf_name.append('tpu_batch_normalization_2')\n",
    "      elif 'expand' in keras_name:\n",
    "        tf_name.append('tpu_batch_normalization')\n",
    "      else:\n",
    "        tf_name.append('tpu_batch_normalization_1')\n",
    "\n",
    "    for x in ['moving_mean', 'moving_variance', 'beta', 'gamma']:\n",
    "      if x in keras_name:\n",
    "        tf_name.append(x)\n",
    "  if use_ema:\n",
    "    tf_name.append('ExponentialMovingAverage')\n",
    "  return '/'.join(tf_name)\n",
    "\n",
    "\n",
    "def check_match(keras_block, tf_block, keras_weight_names, tf_weight_names,\n",
    "                model_name_tf):\n",
    "  \"\"\"Check if the weights in h5 and ckpt match.\n",
    "  we match each name from keras_weight_names that is in keras_block\n",
    "  and check if there is 1-1 correspondence to names from tf_weight_names\n",
    "  that is in tf_block\n",
    "  Args:\n",
    "    keras_block: str, the block name for keras implementation (e.g. 'block1a')\n",
    "    tf_block: str, the block name for tf implementation (e.g. 'blocks_0')\n",
    "    keras_weight_names: list of str, weight names in keras implementation\n",
    "    tf_weight_names: list of str, weight names in tf implementation\n",
    "    model_name_tf: str, the name of model in ckpt.\n",
    "  \"\"\"\n",
    "  names_from_keras = set()\n",
    "  for x in keras_weight_names:\n",
    "    if keras_block in x:\n",
    "      y = keras_name_to_tf_name_block(\n",
    "          x,\n",
    "          keras_block=keras_block,\n",
    "          tf_block=tf_block,\n",
    "          model_name_tf=model_name_tf)\n",
    "      names_from_keras.add(y)\n",
    "\n",
    "  names_from_tf = set()\n",
    "  for x in tf_weight_names:\n",
    "    if tf_block in x and x.split('/')[1].endswith(tf_block):\n",
    "      names_from_tf.add(x)\n",
    "\n",
    "  names_missing = names_from_keras - names_from_tf\n",
    "  if names_missing:\n",
    "    raise ValueError('{} variables not found in checkpoint file: {}'.format(\n",
    "        len(names_missing), names_missing))\n",
    "\n",
    "  names_unused = names_from_tf - names_from_keras\n",
    "  if names_unused:\n",
    "    warnings.warn('{} variables from checkpoint file are not used: {}'.format(\n",
    "        len(names_unused), names_unused))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008846,
     "end_time": "2021-02-15T17:13:47.480383",
     "exception": false,
     "start_time": "2021-02-15T17:13:47.471537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Download checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-output": true,
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-15T17:13:47.519049Z",
     "iopub.status.busy": "2021-02-15T17:13:47.518355Z",
     "iopub.status.idle": "2021-02-15T17:14:23.580285Z",
     "shell.execute_reply": "2021-02-15T17:14:23.579339Z"
    },
    "papermill": {
     "duration": 36.090434,
     "end_time": "2021-02-15T17:14:23.580481",
     "exception": false,
     "start_time": "2021-02-15T17:13:47.490047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-15 17:13:48--  https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b0.tar.gz\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.193.128, 74.125.31.128, 172.217.204.128, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.193.128|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 156406658 (149M) [application/x-tar]\r\n",
      "Saving to: ‘noisy_student_efficientnet-b0.tar.gz’\r\n",
      "\r\n",
      "noisy_student_effic 100%[===================>] 149.16M  81.2MB/s    in 1.8s    \r\n",
      "\r\n",
      "2021-02-15 17:13:50 (81.2 MB/s) - ‘noisy_student_efficientnet-b0.tar.gz’ saved [156406658/156406658]\r\n",
      "\r\n",
      "--2021-02-15 17:13:51--  https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b1.tar.gz\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.217.128, 172.217.193.128, 173.194.216.128, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.217.128|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 57923566 (55M) [application/gzip]\r\n",
      "Saving to: ‘noisy_student_efficientnet-b1.tar.gz’\r\n",
      "\r\n",
      "noisy_student_effic 100%[===================>]  55.24M  50.7MB/s    in 1.1s    \r\n",
      "\r\n",
      "2021-02-15 17:13:53 (50.7 MB/s) - ‘noisy_student_efficientnet-b1.tar.gz’ saved [57923566/57923566]\r\n",
      "\r\n",
      "--2021-02-15 17:13:53--  https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b2.tar.gz\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.217.128, 172.253.123.128, 172.217.204.128, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.217.128|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 67588622 (64M) [application/gzip]\r\n",
      "Saving to: ‘noisy_student_efficientnet-b2.tar.gz’\r\n",
      "\r\n",
      "noisy_student_effic 100%[===================>]  64.46M  53.0MB/s    in 1.2s    \r\n",
      "\r\n",
      "2021-02-15 17:13:55 (53.0 MB/s) - ‘noisy_student_efficientnet-b2.tar.gz’ saved [67588622/67588622]\r\n",
      "\r\n",
      "--2021-02-15 17:13:56--  https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b3.tar.gz\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.217.128, 142.250.97.128, 172.217.203.128, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.217.128|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 90666978 (86M) [application/gzip]\r\n",
      "Saving to: ‘noisy_student_efficientnet-b3.tar.gz’\r\n",
      "\r\n",
      "noisy_student_effic 100%[===================>]  86.47M  63.8MB/s    in 1.4s    \r\n",
      "\r\n",
      "2021-02-15 17:13:58 (63.8 MB/s) - ‘noisy_student_efficientnet-b3.tar.gz’ saved [90666978/90666978]\r\n",
      "\r\n",
      "--2021-02-15 17:13:59--  https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b4.tar.gz\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.128, 172.217.193.128, 173.194.217.128, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.128|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 143203873 (137M) [application/gzip]\r\n",
      "Saving to: ‘noisy_student_efficientnet-b4.tar.gz’\r\n",
      "\r\n",
      "noisy_student_effic 100%[===================>] 136.57M  69.5MB/s    in 2.0s    \r\n",
      "\r\n",
      "2021-02-15 17:14:01 (69.5 MB/s) - ‘noisy_student_efficientnet-b4.tar.gz’ saved [143203873/143203873]\r\n",
      "\r\n",
      "--2021-02-15 17:14:02--  https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b5.tar.gz\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.203.128, 172.253.123.128, 172.217.193.128, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.203.128|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 225123940 (215M) [application/gzip]\r\n",
      "Saving to: ‘noisy_student_efficientnet-b5.tar.gz’\r\n",
      "\r\n",
      "noisy_student_effic 100%[===================>] 214.69M  64.3MB/s    in 3.3s    \r\n",
      "\r\n",
      "2021-02-15 17:14:06 (64.3 MB/s) - ‘noisy_student_efficientnet-b5.tar.gz’ saved [225123940/225123940]\r\n",
      "\r\n",
      "--2021-02-15 17:14:07--  https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b6.tar.gz\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 172.253.123.128, 142.250.97.128, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 318821738 (304M) [application/gzip]\r\n",
      "Saving to: ‘noisy_student_efficientnet-b6.tar.gz’\r\n",
      "\r\n",
      "noisy_student_effic 100%[===================>] 304.05M  54.5MB/s    in 5.6s    \r\n",
      "\r\n",
      "2021-02-15 17:14:13 (54.5 MB/s) - ‘noisy_student_efficientnet-b6.tar.gz’ saved [318821738/318821738]\r\n",
      "\r\n",
      "--2021-02-15 17:14:14--  https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b7.tar.gz\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.217.128, 142.250.97.128, 172.217.193.128, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.217.128|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 491946084 (469M) [application/gzip]\r\n",
      "Saving to: ‘noisy_student_efficientnet-b7.tar.gz’\r\n",
      "\r\n",
      "noisy_student_effic 100%[===================>] 469.16M  59.5MB/s    in 8.4s    \r\n",
      "\r\n",
      "2021-02-15 17:14:23 (56.0 MB/s) - ‘noisy_student_efficientnet-b7.tar.gz’ saved [491946084/491946084]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b0.tar.gz\n",
    "!wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b1.tar.gz\n",
    "!wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b2.tar.gz\n",
    "!wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b3.tar.gz\n",
    "!wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b4.tar.gz\n",
    "!wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b5.tar.gz\n",
    "!wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b6.tar.gz\n",
    "!wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b7.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033321,
     "end_time": "2021-02-15T17:14:23.648423",
     "exception": false,
     "start_time": "2021-02-15T17:14:23.615102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Unzip checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T17:14:23.727207Z",
     "iopub.status.busy": "2021-02-15T17:14:23.726336Z",
     "iopub.status.idle": "2021-02-15T17:14:53.197423Z",
     "shell.execute_reply": "2021-02-15T17:14:53.195367Z"
    },
    "papermill": {
     "duration": 29.513047,
     "end_time": "2021-02-15T17:14:53.197677",
     "exception": false,
     "start_time": "2021-02-15T17:14:23.684630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar -xf noisy_student_efficientnet-b0.tar.gz\n",
    "!tar -xf noisy_student_efficientnet-b1.tar.gz\n",
    "!tar -xf noisy_student_efficientnet-b2.tar.gz\n",
    "!tar -xf noisy_student_efficientnet-b3.tar.gz\n",
    "!tar -xf noisy_student_efficientnet-b4.tar.gz\n",
    "!tar -xf noisy_student_efficientnet-b5.tar.gz\n",
    "!tar -xf noisy_student_efficientnet-b6.tar.gz\n",
    "!tar -xf noisy_student_efficientnet-b7.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.05951,
     "end_time": "2021-02-15T17:14:53.317486",
     "exception": false,
     "start_time": "2021-02-15T17:14:53.257976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Convert checkpoints to .h5 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-15T17:14:53.439457Z",
     "iopub.status.busy": "2021-02-15T17:14:53.438686Z",
     "iopub.status.idle": "2021-02-15T17:14:58.895366Z",
     "shell.execute_reply": "2021-02-15T17:14:58.897118Z"
    },
    "papermill": {
     "duration": 5.524111,
     "end_time": "2021-02-15T17:14:58.897795",
     "exception": false,
     "start_time": "2021-02-15T17:14:53.373684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16711680/16705208 [==============================] - 1s 0us/step\n",
      "check variables match in each block\n",
      "blocks_0 and block1a match.\n",
      "blocks_1 and block2a match.\n",
      "blocks_2 and block2b match.\n",
      "blocks_3 and block3a match.\n",
      "blocks_4 and block3b match.\n",
      "blocks_5 and block4a match.\n",
      "blocks_6 and block4b match.\n",
      "blocks_7 and block4c match.\n",
      "blocks_8 and block5a match.\n",
      "blocks_9 and block5b match.\n",
      "blocks_10 and block5c match.\n",
      "blocks_11 and block6a match.\n",
      "blocks_12 and block6b match.\n",
      "blocks_13 and block6c match.\n",
      "blocks_14 and block6d match.\n",
      "blocks_15 and block7a match.\n",
      "skipping variable normalization/mean:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization/variance:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization/count:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "309/312 weights updated\n"
     ]
    }
   ],
   "source": [
    "write_ckpt_to_h5('efficientnetb0_notop.h5', \n",
    "                 'noisy_student_efficientnet-b0/model.ckpt', \n",
    "                 keras_model=efficientnet.EfficientNetB0(include_top=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-15T17:14:59.444463Z",
     "iopub.status.busy": "2021-02-15T17:14:59.443521Z",
     "iopub.status.idle": "2021-02-15T17:15:06.607559Z",
     "shell.execute_reply": "2021-02-15T17:15:06.605525Z"
    },
    "papermill": {
     "duration": 7.538899,
     "end_time": "2021-02-15T17:15:06.607762",
     "exception": false,
     "start_time": "2021-02-15T17:14:59.068863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n",
      "27025408/27018416 [==============================] - 1s 0us/step\n",
      "check variables match in each block\n",
      "blocks_0 and block1a match.\n",
      "blocks_1 and block1b match.\n",
      "blocks_2 and block2a match.\n",
      "blocks_3 and block2b match.\n",
      "blocks_4 and block2c match.\n",
      "blocks_5 and block3a match.\n",
      "blocks_6 and block3b match.\n",
      "blocks_7 and block3c match.\n",
      "blocks_8 and block4a match.\n",
      "blocks_9 and block4b match.\n",
      "blocks_10 and block4c match.\n",
      "blocks_11 and block4d match.\n",
      "blocks_12 and block5a match.\n",
      "blocks_13 and block5b match.\n",
      "blocks_14 and block5c match.\n",
      "blocks_15 and block5d match.\n",
      "blocks_16 and block6a match.\n",
      "blocks_17 and block6b match.\n",
      "blocks_18 and block6c match.\n",
      "blocks_19 and block6d match.\n",
      "blocks_20 and block6e match.\n",
      "blocks_21 and block7a match.\n",
      "blocks_22 and block7b match.\n",
      "skipping variable normalization_1/mean:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization_1/variance:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization_1/count:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "437/440 weights updated\n"
     ]
    }
   ],
   "source": [
    "write_ckpt_to_h5('efficientnetb1_notop.h5', \n",
    "                 'noisy-student-efficientnet-b1/model.ckpt', \n",
    "                 keras_model=efficientnet.EfficientNetB1(include_top=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-15T17:15:06.726979Z",
     "iopub.status.busy": "2021-02-15T17:15:06.724850Z",
     "iopub.status.idle": "2021-02-15T17:15:12.273588Z",
     "shell.execute_reply": "2021-02-15T17:15:12.272815Z"
    },
    "papermill": {
     "duration": 5.606731,
     "end_time": "2021-02-15T17:15:12.273771",
     "exception": false,
     "start_time": "2021-02-15T17:15:06.667040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb2_notop.h5\n",
      "31793152/31790344 [==============================] - 1s 0us/step\n",
      "check variables match in each block\n",
      "blocks_0 and block1a match.\n",
      "blocks_1 and block1b match.\n",
      "blocks_2 and block2a match.\n",
      "blocks_3 and block2b match.\n",
      "blocks_4 and block2c match.\n",
      "blocks_5 and block3a match.\n",
      "blocks_6 and block3b match.\n",
      "blocks_7 and block3c match.\n",
      "blocks_8 and block4a match.\n",
      "blocks_9 and block4b match.\n",
      "blocks_10 and block4c match.\n",
      "blocks_11 and block4d match.\n",
      "blocks_12 and block5a match.\n",
      "blocks_13 and block5b match.\n",
      "blocks_14 and block5c match.\n",
      "blocks_15 and block5d match.\n",
      "blocks_16 and block6a match.\n",
      "blocks_17 and block6b match.\n",
      "blocks_18 and block6c match.\n",
      "blocks_19 and block6d match.\n",
      "blocks_20 and block6e match.\n",
      "blocks_21 and block7a match.\n",
      "blocks_22 and block7b match.\n",
      "skipping variable normalization_2/mean:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization_2/variance:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization_2/count:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "437/440 weights updated\n"
     ]
    }
   ],
   "source": [
    "write_ckpt_to_h5('efficientnetb2_notop.h5', \n",
    "                 'noisy-student-efficientnet-b2/model.ckpt', \n",
    "                 keras_model=efficientnet.EfficientNetB2(include_top=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-15T17:15:12.370239Z",
     "iopub.status.busy": "2021-02-15T17:15:12.369202Z",
     "iopub.status.idle": "2021-02-15T17:15:18.400473Z",
     "shell.execute_reply": "2021-02-15T17:15:18.399900Z"
    },
    "papermill": {
     "duration": 6.083509,
     "end_time": "2021-02-15T17:15:18.400678",
     "exception": false,
     "start_time": "2021-02-15T17:15:12.317169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
      "43941888/43941136 [==============================] - 0s 0us/step\n",
      "check variables match in each block\n",
      "blocks_0 and block1a match.\n",
      "blocks_1 and block1b match.\n",
      "blocks_2 and block2a match.\n",
      "blocks_3 and block2b match.\n",
      "blocks_4 and block2c match.\n",
      "blocks_5 and block3a match.\n",
      "blocks_6 and block3b match.\n",
      "blocks_7 and block3c match.\n",
      "blocks_8 and block4a match.\n",
      "blocks_9 and block4b match.\n",
      "blocks_10 and block4c match.\n",
      "blocks_11 and block4d match.\n",
      "blocks_12 and block4e match.\n",
      "blocks_13 and block5a match.\n",
      "blocks_14 and block5b match.\n",
      "blocks_15 and block5c match.\n",
      "blocks_16 and block5d match.\n",
      "blocks_17 and block5e match.\n",
      "blocks_18 and block6a match.\n",
      "blocks_19 and block6b match.\n",
      "blocks_20 and block6c match.\n",
      "blocks_21 and block6d match.\n",
      "blocks_22 and block6e match.\n",
      "blocks_23 and block6f match.\n",
      "blocks_24 and block7a match.\n",
      "blocks_25 and block7b match.\n",
      "skipping variable normalization_3/mean:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization_3/variance:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization_3/count:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "494/497 weights updated\n"
     ]
    }
   ],
   "source": [
    "write_ckpt_to_h5('efficientnetb3_notop.h5', \n",
    "                 'noisy-student-efficientnet-b3/model.ckpt', \n",
    "                 keras_model=efficientnet.EfficientNetB3(include_top=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-15T17:15:18.503559Z",
     "iopub.status.busy": "2021-02-15T17:15:18.501851Z",
     "iopub.status.idle": "2021-02-15T17:15:27.229955Z",
     "shell.execute_reply": "2021-02-15T17:15:27.230557Z"
    },
    "papermill": {
     "duration": 8.785326,
     "end_time": "2021-02-15T17:15:27.230789",
     "exception": false,
     "start_time": "2021-02-15T17:15:18.445463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
      "71688192/71686520 [==============================] - 1s 0us/step\n",
      "check variables match in each block\n",
      "blocks_0 and block1a match.\n",
      "blocks_1 and block1b match.\n",
      "blocks_2 and block2a match.\n",
      "blocks_3 and block2b match.\n",
      "blocks_4 and block2c match.\n",
      "blocks_5 and block2d match.\n",
      "blocks_6 and block3a match.\n",
      "blocks_7 and block3b match.\n",
      "blocks_8 and block3c match.\n",
      "blocks_9 and block3d match.\n",
      "blocks_10 and block4a match.\n",
      "blocks_11 and block4b match.\n",
      "blocks_12 and block4c match.\n",
      "blocks_13 and block4d match.\n",
      "blocks_14 and block4e match.\n",
      "blocks_15 and block4f match.\n",
      "blocks_16 and block5a match.\n",
      "blocks_17 and block5b match.\n",
      "blocks_18 and block5c match.\n",
      "blocks_19 and block5d match.\n",
      "blocks_20 and block5e match.\n",
      "blocks_21 and block5f match.\n",
      "blocks_22 and block6a match.\n",
      "blocks_23 and block6b match.\n",
      "blocks_24 and block6c match.\n",
      "blocks_25 and block6d match.\n",
      "blocks_26 and block6e match.\n",
      "blocks_27 and block6f match.\n",
      "blocks_28 and block6g match.\n",
      "blocks_29 and block6h match.\n",
      "blocks_30 and block7a match.\n",
      "blocks_31 and block7b match.\n",
      "skipping variable normalization_4/mean:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization_4/variance:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization_4/count:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "608/611 weights updated\n"
     ]
    }
   ],
   "source": [
    "write_ckpt_to_h5('efficientnetb4_notop.h5', \n",
    "                 'noisy-student-efficientnet-b4/model.ckpt', \n",
    "                 keras_model=efficientnet.EfficientNetB4(include_top=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-15T17:15:27.342970Z",
     "iopub.status.busy": "2021-02-15T17:15:27.340847Z",
     "iopub.status.idle": "2021-02-15T17:15:39.744466Z",
     "shell.execute_reply": "2021-02-15T17:15:39.745025Z"
    },
    "papermill": {
     "duration": 12.464526,
     "end_time": "2021-02-15T17:15:39.745251",
     "exception": false,
     "start_time": "2021-02-15T17:15:27.280725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5_notop.h5\n",
      "115269632/115263384 [==============================] - 2s 0us/step\n",
      "check variables match in each block\n",
      "blocks_0 and block1a match.\n",
      "blocks_1 and block1b match.\n",
      "blocks_2 and block1c match.\n",
      "blocks_3 and block2a match.\n",
      "blocks_4 and block2b match.\n",
      "blocks_5 and block2c match.\n",
      "blocks_6 and block2d match.\n",
      "blocks_7 and block2e match.\n",
      "blocks_8 and block3a match.\n",
      "blocks_9 and block3b match.\n",
      "blocks_10 and block3c match.\n",
      "blocks_11 and block3d match.\n",
      "blocks_12 and block3e match.\n",
      "blocks_13 and block4a match.\n",
      "blocks_14 and block4b match.\n",
      "blocks_15 and block4c match.\n",
      "blocks_16 and block4d match.\n",
      "blocks_17 and block4e match.\n",
      "blocks_18 and block4f match.\n",
      "blocks_19 and block4g match.\n",
      "blocks_20 and block5a match.\n",
      "blocks_21 and block5b match.\n",
      "blocks_22 and block5c match.\n",
      "blocks_23 and block5d match.\n",
      "blocks_24 and block5e match.\n",
      "blocks_25 and block5f match.\n",
      "blocks_26 and block5g match.\n",
      "blocks_27 and block6a match.\n",
      "blocks_28 and block6b match.\n",
      "blocks_29 and block6c match.\n",
      "blocks_30 and block6d match.\n",
      "blocks_31 and block6e match.\n",
      "blocks_32 and block6f match.\n",
      "blocks_33 and block6g match.\n",
      "blocks_34 and block6h match.\n",
      "blocks_35 and block6i match.\n",
      "blocks_36 and block7a match.\n",
      "blocks_37 and block7b match.\n",
      "blocks_38 and block7c match.\n",
      "skipping variable normalization_5/mean:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization_5/variance:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization_5/count:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "736/739 weights updated\n"
     ]
    }
   ],
   "source": [
    "write_ckpt_to_h5('efficientnetb5_notop.h5', \n",
    "                 'noisy-student-efficientnet-b5/model.ckpt', \n",
    "                 keras_model=efficientnet.EfficientNetB5(include_top=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-15T17:15:39.862634Z",
     "iopub.status.busy": "2021-02-15T17:15:39.861976Z",
     "iopub.status.idle": "2021-02-15T17:15:55.980780Z",
     "shell.execute_reply": "2021-02-15T17:15:55.979600Z"
    },
    "papermill": {
     "duration": 16.178989,
     "end_time": "2021-02-15T17:15:55.980980",
     "exception": false,
     "start_time": "2021-02-15T17:15:39.801991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb6_notop.h5\n",
      "165240832/165234480 [==============================] - 3s 0us/step\n",
      "check variables match in each block\n",
      "blocks_0 and block1a match.\n",
      "blocks_1 and block1b match.\n",
      "blocks_2 and block1c match.\n",
      "blocks_3 and block2a match.\n",
      "blocks_4 and block2b match.\n",
      "blocks_5 and block2c match.\n",
      "blocks_6 and block2d match.\n",
      "blocks_7 and block2e match.\n",
      "blocks_8 and block2f match.\n",
      "blocks_9 and block3a match.\n",
      "blocks_10 and block3b match.\n",
      "blocks_11 and block3c match.\n",
      "blocks_12 and block3d match.\n",
      "blocks_13 and block3e match.\n",
      "blocks_14 and block3f match.\n",
      "blocks_15 and block4a match.\n",
      "blocks_16 and block4b match.\n",
      "blocks_17 and block4c match.\n",
      "blocks_18 and block4d match.\n",
      "blocks_19 and block4e match.\n",
      "blocks_20 and block4f match.\n",
      "blocks_21 and block4g match.\n",
      "blocks_22 and block4h match.\n",
      "blocks_23 and block5a match.\n",
      "blocks_24 and block5b match.\n",
      "blocks_25 and block5c match.\n",
      "blocks_26 and block5d match.\n",
      "blocks_27 and block5e match.\n",
      "blocks_28 and block5f match.\n",
      "blocks_29 and block5g match.\n",
      "blocks_30 and block5h match.\n",
      "blocks_31 and block6a match.\n",
      "blocks_32 and block6b match.\n",
      "blocks_33 and block6c match.\n",
      "blocks_34 and block6d match.\n",
      "blocks_35 and block6e match.\n",
      "blocks_36 and block6f match.\n",
      "blocks_37 and block6g match.\n",
      "blocks_38 and block6h match.\n",
      "blocks_39 and block6i match.\n",
      "blocks_40 and block6j match.\n",
      "blocks_41 and block6k match.\n",
      "blocks_42 and block7a match.\n",
      "blocks_43 and block7b match.\n",
      "blocks_44 and block7c match.\n",
      "skipping variable normalization_6/mean:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization_6/variance:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization_6/count:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "850/853 weights updated\n"
     ]
    }
   ],
   "source": [
    "write_ckpt_to_h5('efficientnetb6_notop.h5', \n",
    "                 'noisy-student-efficientnet-b6/model.ckpt', \n",
    "                 keras_model=efficientnet.EfficientNetB6(include_top=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-15T17:15:56.125269Z",
     "iopub.status.busy": "2021-02-15T17:15:56.124240Z",
     "iopub.status.idle": "2021-02-15T17:16:16.872885Z",
     "shell.execute_reply": "2021-02-15T17:16:16.873592Z"
    },
    "papermill": {
     "duration": 20.82294,
     "end_time": "2021-02-15T17:16:16.873888",
     "exception": false,
     "start_time": "2021-02-15T17:15:56.050948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
      "258080768/258076736 [==============================] - 4s 0us/step\n",
      "check variables match in each block\n",
      "blocks_0 and block1a match.\n",
      "blocks_1 and block1b match.\n",
      "blocks_2 and block1c match.\n",
      "blocks_3 and block1d match.\n",
      "blocks_4 and block2a match.\n",
      "blocks_5 and block2b match.\n",
      "blocks_6 and block2c match.\n",
      "blocks_7 and block2d match.\n",
      "blocks_8 and block2e match.\n",
      "blocks_9 and block2f match.\n",
      "blocks_10 and block2g match.\n",
      "blocks_11 and block3a match.\n",
      "blocks_12 and block3b match.\n",
      "blocks_13 and block3c match.\n",
      "blocks_14 and block3d match.\n",
      "blocks_15 and block3e match.\n",
      "blocks_16 and block3f match.\n",
      "blocks_17 and block3g match.\n",
      "blocks_18 and block4a match.\n",
      "blocks_19 and block4b match.\n",
      "blocks_20 and block4c match.\n",
      "blocks_21 and block4d match.\n",
      "blocks_22 and block4e match.\n",
      "blocks_23 and block4f match.\n",
      "blocks_24 and block4g match.\n",
      "blocks_25 and block4h match.\n",
      "blocks_26 and block4i match.\n",
      "blocks_27 and block4j match.\n",
      "blocks_28 and block5a match.\n",
      "blocks_29 and block5b match.\n",
      "blocks_30 and block5c match.\n",
      "blocks_31 and block5d match.\n",
      "blocks_32 and block5e match.\n",
      "blocks_33 and block5f match.\n",
      "blocks_34 and block5g match.\n",
      "blocks_35 and block5h match.\n",
      "blocks_36 and block5i match.\n",
      "blocks_37 and block5j match.\n",
      "blocks_38 and block6a match.\n",
      "blocks_39 and block6b match.\n",
      "blocks_40 and block6c match.\n",
      "blocks_41 and block6d match.\n",
      "blocks_42 and block6e match.\n",
      "blocks_43 and block6f match.\n",
      "blocks_44 and block6g match.\n",
      "blocks_45 and block6h match.\n",
      "blocks_46 and block6i match.\n",
      "blocks_47 and block6j match.\n",
      "blocks_48 and block6k match.\n",
      "blocks_49 and block6l match.\n",
      "blocks_50 and block6m match.\n",
      "blocks_51 and block7a match.\n",
      "blocks_52 and block7b match.\n",
      "blocks_53 and block7c match.\n",
      "blocks_54 and block7d match.\n",
      "skipping variable normalization_7/mean:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization_7/variance:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "skipping variable normalization_7/count:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
      "1035/1038 weights updated\n"
     ]
    }
   ],
   "source": [
    "write_ckpt_to_h5('efficientnetb7_notop.h5', \n",
    "                 'noisy-student-efficientnet-b7/model.ckpt', \n",
    "                 keras_model=efficientnet.EfficientNetB7(include_top=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.076792,
     "end_time": "2021-02-15T17:16:17.029688",
     "exception": false,
     "start_time": "2021-02-15T17:16:16.952896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-15T17:16:17.208565Z",
     "iopub.status.busy": "2021-02-15T17:16:17.192816Z",
     "iopub.status.idle": "2021-02-15T17:16:30.118104Z",
     "shell.execute_reply": "2021-02-15T17:16:30.118601Z"
    },
    "papermill": {
     "duration": 13.011871,
     "end_time": "2021-02-15T17:16:30.118854",
     "exception": false,
     "start_time": "2021-02-15T17:16:17.106983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Files\n",
    "!rm noisy_student_efficientnet-b0.tar.gz\n",
    "!rm noisy_student_efficientnet-b1.tar.gz\n",
    "!rm noisy_student_efficientnet-b2.tar.gz\n",
    "!rm noisy_student_efficientnet-b3.tar.gz\n",
    "!rm noisy_student_efficientnet-b4.tar.gz\n",
    "!rm noisy_student_efficientnet-b5.tar.gz\n",
    "!rm noisy_student_efficientnet-b6.tar.gz\n",
    "!rm noisy_student_efficientnet-b7.tar.gz\n",
    "\n",
    "# Directories\n",
    "!rm -r noisy_student_efficientnet-b0\n",
    "!rm -r noisy-student-efficientnet-b1\n",
    "!rm -r noisy-student-efficientnet-b2\n",
    "!rm -r noisy-student-efficientnet-b3\n",
    "!rm -r noisy-student-efficientnet-b4\n",
    "!rm -r noisy-student-efficientnet-b5\n",
    "!rm -r noisy-student-efficientnet-b6\n",
    "!rm -r noisy-student-efficientnet-b7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 177.391235,
   "end_time": "2021-02-15T17:16:32.413452",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-15T17:13:35.022217",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
